{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/ag-news-classification-dataset/train.csv\n/kaggle/input/ag-news-classification-dataset/test.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\n# Install java\n! apt-get update -qq\n! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\nos.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n! java -version\n\n# Install pyspark\n! pip install --ignore-installed -q pyspark==2.4.4\n! pip install --ignore-installed -q spark-nlp==2.7.1","execution_count":2,"outputs":[{"output_type":"stream","text":"debconf: delaying package configuration, since apt-utils is not installed\nopenjdk version \"1.8.0_282\"\nOpenJDK Runtime Environment (build 1.8.0_282-8u282-b08-0ubuntu1~18.04-b08)\nOpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sparknlp\n\nspark = sparknlp.start(gpu = True) # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n\nfrom sparknlp.base import *\nfrom sparknlp.annotator import *\nfrom pyspark.ml import Pipeline\nimport pandas as pd\n\nprint(\"Spark NLP version\", sparknlp.version())\n\nprint(\"Apache Spark version:\", spark.version)\n\nspark","execution_count":3,"outputs":[{"output_type":"stream","text":"Spark NLP version 2.7.1\nApache Spark version: 2.4.4\n","name":"stdout"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"<pyspark.sql.session.SparkSession at 0x7fe6e058f050>","text/html":"\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://ead999991a1c:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Spark NLP</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = spark.read \\\n      .option(\"header\", True) \\\n      .csv(\"/kaggle/input/ag-news-classification-dataset/train.csv\")\n\ndf.show(truncate=50)","execution_count":4,"outputs":[{"output_type":"stream","text":"+-----------+--------------------------------------------------+--------------------------------------------------+\n|Class Index|                                             Title|                                       Description|\n+-----------+--------------------------------------------------+--------------------------------------------------+\n|          3| Wall St. Bears Claw Back Into the Black (Reuters)|Reuters - Short-sellers, Wall Street's dwindlin...|\n|          3|Carlyle Looks Toward Commercial Aerospace (Reut...|Reuters - Private investment firm Carlyle Group...|\n|          3|   Oil and Economy Cloud Stocks' Outlook (Reuters)|Reuters - Soaring crude prices plus worries\\abo...|\n|          3|Iraq Halts Oil Exports from Main Southern Pipel...|Reuters - Authorities have halted oil export\\fl...|\n|          3|Oil prices soar to all-time record, posing new ...|AFP - Tearaway world oil prices, toppling recor...|\n|          3|       Stocks End Up, But Near Year Lows (Reuters)|Reuters - Stocks ended slightly higher on Frida...|\n|          3|              Money Funds Fell in Latest Week (AP)|AP - Assets of the nation's retail money market...|\n|          3|Fed minutes show dissent over inflation (USATOD...|USATODAY.com - Retail sales bounced back a bit ...|\n|          3|                           Safety Net (Forbes.com)|\"Forbes.com - After earning a PH.D. in Sociolog...|\n|          3|           Wall St. Bears Claw Back Into the Black| NEW YORK (Reuters) - Short-sellers, Wall Stree...|\n|          3|             Oil and Economy Cloud Stocks' Outlook| NEW YORK (Reuters) - Soaring crude prices plus...|\n|          3|            No Need for OPEC to Pump More-Iran Gov| TEHRAN (Reuters) - OPEC can do nothing to dous...|\n|          3|         Non-OPEC Nations Should Up Output-Purnomo| JAKARTA (Reuters) - Non-OPEC oil exporters sho...|\n|          3|             Google IPO Auction Off to Rocky Start| WASHINGTON/NEW YORK (Reuters) - The auction fo...|\n|          3|          Dollar Falls Broadly on Record Trade Gap| NEW YORK (Reuters) - The dollar tumbled broadl...|\n|          3|                             Rescuing an Old Saver|If you think you may need to help your elderly ...|\n|          3|                      Kids Rule for Back-to-School|The purchasing power of kids is a big part of w...|\n|          3|         In a Down Market, Head Toward Value Funds|There is little cause for celebration in the st...|\n|          3|                   US trade deficit swells in June|The US trade deficit has exploded 19 to a recor...|\n|          3|                 Shell 'could be target for Total'|Oil giant Shell could be bracing itself for a t...|\n+-----------+--------------------------------------------------+--------------------------------------------------+\nonly showing top 20 rows\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.count()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"120000"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.sql.functions import col\n\ndf.groupBy(\"Class Index\") \\\n    .count() \\\n    .orderBy(col(\"count\").desc()) \\\n    .show()","execution_count":7,"outputs":[{"output_type":"stream","text":"+-----------+-----+\n|Class Index|count|\n+-----------+-----+\n|          1|30000|\n|          4|30000|\n|          3|30000|\n|          2|30000|\n+-----------+-----+\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_df, val_df) = df.randomSplit([0.7, 0.3], seed = 8)\nprint(\"Training Dataset Count: \" + str(train_df.count()))\nprint(\"Validation Dataset Count: \" + str(val_df.count()))","execution_count":8,"outputs":[{"output_type":"stream","text":"Training Dataset Count: 84042\nValidation Dataset Count: 35958\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# actual content is inside description column\ndocument = DocumentAssembler() \\\n.setInputCol(\"Description\") \\\n.setOutputCol(\"document\") \\\n.setCleanupMode(\"shrink\")\n\nbert = BertSentenceEmbeddings.pretrained('sent_bert_base_cased') \\\n.setInputCols(\"document\") \\\n.setOutputCol(\"bert_sentence_embeddings\") \\\n.setLazyAnnotator(False)\n\n# the classes/labels/categories are in category column\nclassifierdl = ClassifierDLApproach()\\\n.setInputCols([\"bert_sentence_embeddings\"])\\\n.setOutputCol(\"class\")\\\n.setLabelColumn(\"Class Index\")\\\n.setMaxEpochs(5)\\\n.setLr(0.001)\\\n.setBatchSize(8)\\\n.setEnableOutputLogs(True)\n#.setOutputLogsPath('logs')\n\npipeline = Pipeline(\n    stages = [\n        document,\n        bert,\n        classifierdl\n    ])","execution_count":9,"outputs":[{"output_type":"stream","text":"sent_bert_base_cased download started this may take some time.\nApproximate size to download 389.1 MB\n[OK!]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npipelineModel = pipeline.fit(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the predictions on validation Set\n\npreds = pipelineModel.transform(val_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds.select('Description','Class Index',\"class.result\").show(10, truncate=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df = preds.select('Description','Class Index',\"class.result\").toPandas()\n\n# The result is an array since in Spark NLP you can have multiple sentences.\n# Let's explode the array and get the item(s) inside of result column out\npreds_df['result'] = preds_df['result'].apply(lambda x : x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are going to use sklearn to evalute the results on test dataset\nfrom sklearn.metrics import classification_report\n\nprint (classification_report(preds_df['result'], preds_df['Class Index']))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}